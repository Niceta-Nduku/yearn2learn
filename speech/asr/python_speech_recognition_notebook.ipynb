{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "python_speech_recognition_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPFXeLzR1onT4EHtzs8/BSS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scgupta/yearn2learn/blob/master/speech/asr/python_speech_recognition_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhBo4UlPaq4O",
        "colab_type": "text"
      },
      "source": [
        "# Speech Recognition in Python\n",
        "\n",
        "There are several speech recognition systems with Python bindings or library. The [SpeechRecognition](https://pypi.org/project/SpeechRecognition/) package provide a nice abstraction over those. In this notebook we explore using CMU Sphinx (an offline model, i.e. running locally), and Google (an offline model, i.e. over the network/cloud), but through SpeechRecognition package APIs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aqlb4wEcdOx",
        "colab_type": "text"
      },
      "source": [
        "## Setup\n",
        "\n",
        "We need to install SpeechRecognition and pocketsphinx python packages, and download some files to test these APIs.\n",
        "\n",
        "1. **Install SpeechRecognition py package**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ0rokUuby2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install SpeechRecognition"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpFEoLqdOd_3",
        "colab_type": "text"
      },
      "source": [
        "2. **Install Pocketsphinx**\n",
        "[Pocketsphinx](https://pypi.org/project/pocketsphinx/) is python bindings for [CMU Sphinx](https://cmusphinx.github.io/), and is one of the recognizer supported by SpeechRecognition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZy7vLCKTQIp",
        "colab_type": "text"
      },
      "source": [
        "On MacOS: (using homebew):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgpe0kWlTTGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!brew install swig\n",
        "!swig -version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-BnUq7KTJSF",
        "colab_type": "text"
      },
      "source": [
        "On Linux:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58gUVIL7Q5K4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install -y swig libpulse-dev\n",
        "!swig -version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tom0Jb8YVEkZ",
        "colab_type": "text"
      },
      "source": [
        "Now pip install poocketsphinx"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_OHx87yP52E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install pocketsphinx\n",
        "!pip3 list | grep pocketsphinx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6wehMM8XYyz",
        "colab_type": "text"
      },
      "source": [
        "3. **Download audio samples**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5HVQXkpCcWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.6.0/audio-0.6.0.tar.gz\n",
        "!tar -xvzf audio-0.6.0.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsC-yynmC6uA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -l ./audio/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piIB_P7CXey4",
        "colab_type": "text"
      },
      "source": [
        "# SpeechRecognition API\n",
        "\n",
        "SpeechRecognition has only batch API. First step to create an audio record, eithher from a file or from mic, and the second step is to call `recognize_<speech engine name>()` function. It currently has APIs for [CMU Sphinx, Google, Microsoft, IBM, Houndify, and Wit](https://github.com/Uberi/speech_recognition).\n",
        "\n",
        "1. **Import `speech_recognition` package, and create recognizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBpWh7_KYhzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import speech_recognition as sr\n",
        "print(sr.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiWiDR7RaZfQ",
        "colab_type": "text"
      },
      "source": [
        "2. **Speech-To-Text steps**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aia5lFgb-vV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from enum import Enum, unique\n",
        "\n",
        "@unique\n",
        "class ASREngine(Enum):\n",
        "    sphinx = 0\n",
        "    google = 1\n",
        "\n",
        "def speech_to_text(filename: str, engine: ASREngine, language: str, show_all: bool = False) -> str:\n",
        "  r = sr.Recognizer()\n",
        "\n",
        "  with sr.AudioFile(filename) as source:\n",
        "    audio = r.record(source)\n",
        "\n",
        "  asr_functions = {\n",
        "      ASREngine.sphinx: r.recognize_sphinx,\n",
        "      ASREngine.google: r.recognize_google,\n",
        "  }\n",
        "\n",
        "  response = asr_functions[engine](audio, language=language, show_all=show_all)\n",
        "\n",
        "  return response"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-OrriL-djz0",
        "colab_type": "text"
      },
      "source": [
        "3. **Run various speech recognition engines**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f_i1xyVah53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testcases = [\n",
        "  {\n",
        "    'filename': 'audio/2830-3980-0043.wav',\n",
        "    'text': 'experience proves this',\n",
        "    'lang': 'en-US'\n",
        "  },\n",
        "  {\n",
        "    'filename': 'audio/4507-16021-0012.wav',\n",
        "    'text': 'why should one halt on the way',\n",
        "    'lang': 'en-US'\n",
        "  },\n",
        "  {\n",
        "    'filename': 'audio/8455-210777-0068.wav',\n",
        "    'text': 'your power is sufficient i said',\n",
        "    'lang': 'en-US'\n",
        "  }\n",
        "]\n",
        "\n",
        "for t in testcases:\n",
        "  filename = t['filename']\n",
        "  text = t['text']\n",
        "  lang = t['lang']\n",
        "\n",
        "  print('audio file=\"{0}\"    expected text=\"{1}\"'.format(filename, text))\n",
        "  for asr_engine in ASREngine:\n",
        "    try:\n",
        "      response = speech_to_text(filename, asr_engine, language=lang)\n",
        "      print('{0}: \"{1}\"'.format(asr_engine.name, response))\n",
        "    except sr.UnknownValueError:\n",
        "      print('{0} could not understand audio'.format(asr_engine.name))\n",
        "    except sr.RequestError as e:\n",
        "      print('{0} error: {0}'.format(asr_engine.name, e))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66lLoLCaL_nE",
        "colab_type": "text"
      },
      "source": [
        "Notice the difference in results from sniphix and google.\n",
        "\n",
        "# Further Readings\n",
        "\n",
        "For other speech recognition, you will need to create API credentials, which you have to pass to `recognize_<speech engine name>()`, you can checkout [this example](https://github.com/Uberi/speech_recognition/blob/master/examples/audio_transcribe.py).\n",
        "\n",
        "It also has a nice abstraction for Microphone, implemented over [PyAudio](https://people.csail.mit.edu/hubert/pyaudio/) and [PortAudio](http://www.portaudio.com/). Here is an example to capture input from mic in [batch](https://github.com/Uberi/speech_recognition/blob/master/examples/microphone_recognition.py) and continously in [background](https://github.com/Uberi/speech_recognition/blob/master/examples/background_listening.py)."
      ]
    }
  ]
}